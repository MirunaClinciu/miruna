<!DOCTYPE html>
<html lang="en">
<head>
	<meta name="google-adsense-account" content="ca-pub-8894900751182897">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8894900751182897"
     crossorigin="anonymous"></script>
   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

	<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WBZDK0D7YL"></script>
	
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WBZDK0D7YL');
</script>
  <title>Miruna Clinciu</title>
<meta name="description" content="Miruna Clinciu">
<meta name="keywords" content="Miruna Clinciu, explainable, explanations, XAI, Explainable AI, interpretability, terminology, trust, fairness, LLM, large language models, ChatGPT, GPT4, GPT5">
<meta name="robots" content="index, follow">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="language" content="English">
<meta name="author" content="Miruna Clinciu">
<meta name="google-site-verification" content="0Hfuyb4ymv1JMajlBPr0ZUYvu_UY5Fc1MZAL5X0Mpw4" />



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <link href="../stuff/stylenav.css" rel="stylesheet" type="text/css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
	
	<link href="https://fonts.googleapis.com/css?family=Lato&display=swap" rel="stylesheet" type="text/css">
	<link type="text/css" rel="stylesheet" href="jsmind.css" />
<script type="text/javascript" src="jsmind.js"></script>
<script src="https://d3js.org/d3.v5.min.js"></script>
<script src="https://d3js.org/d3.v7.min.js"></script>

	<style>
    .font-blog {
      margin-bottom: 20px;
    }
	.chapter-content {
  font-family: "Georgia", "Times New Roman", serif;
  font-size: 16px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  margin: 2em;
}

.chapter-content.p {
  text-indent: 1.5em;
  margin-bottom: 1.5em;
  max-width: 65ch;
}

h1, h2, h3 {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-weight: 600;
  margin-top: 2em;
  margin-bottom: 1em;
  line-height: 1.2;
}

		.responsive-image {
    float: right;
/*    width: 40%;  Adjust as needed for responsiveness */
/*     background-color: #999;
    color: white; */
    text-align: center;
    padding: 80px 0; /* Adjust vertical padding to control height */
    margin-left: 20px; /* Space between image and text */
    margin-bottom: 20px; /* Space below image */
    box-sizing: border-box; /* Include padding in the element's total width and height */
}

/* Clearfix hack to contain floats */
.clearfix::after {
    content: "";
    display: table;
    clear: both;
}

/* Basic styling for paragraphs */
p {
    margin-bottom: 1em;
}

/* Optional: for smaller screens, make the image take full width */
@media (max-width: 768px) {
    .responsive-image {
        float: none;
        width: 100%;
        margin-left: 0;
        margin-top: 20px;
    }
}
  </style>

</head>
<body>

<nav class="navbar navbar-default navbar-fixed-top navbar-customclass">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/index.html#" style="color: #BC2F31"><strong>Miruna Clinciu</strong></a>

      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      <sapn class="icon-bar"></sapn>
      </button>
    </div>
    <ul class="nav navbar-nav navbar-right collapse navbar-collapse">
      <li class="active"><a href="/index.html#about">About me</a></li>
	      <li><a href="/index.html#news">News</a></li>
      <li><a href="/index.html#research">Research</a></li>
      <li><a href="/experiences.html">Experiences</a></li>
	<li><a href="/blog.html">Blog</a></li>
	<li><a href="/art.html">Art</a></li>
    </ul>
  </div>
</nav>


<div class="container">
<div class="container-fluid">
	<div class="row" id="article">  
		 <div class="font-blog">
<!--Here you modify article title-->
</div></div>
			

	
<!--Here I start article content-->
	
				 <div class="container-fluid pull-right">  <a href="https://www.buymeacoffee.com/miruna"><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=&slug=miruna&button_colour=080808&font_colour=ffffff&font_family=Cookie&outline_colour=ffffff&coffee_colour=FFDD00"/></a>

			 </div>
 <div id="Some words" class="chapter">
        <div class="chapter-header">
          <h3>Generative AI, focus on LLMs</h3>
					  <p>Important! Not all generative AI is classified as LLMs.</p>


	
				 <hr class="hr2"> 
        </div>
	 
      <div class="chapter-content">
			
		<center>	<h3>Generative AI, focus on LLMs</h3>
		</center>
			<br>
          <p><strong>Generative Artificial Intelligence</strong> (<strong>Generative AI</strong>, <strong>GenAI </strong>or <strong>GAI</strong>) is a subfield of AI that uses generative models to produce text, images, videos or any other form of data. <br></p>
			  
          <strong> Large Language Models (LLMs)</strong> can be seen as a subset of GenAI, focusing specifically on  natural language processing and generation tasks.<br>
          
			  To share a bit more, we also have some amazing Multimodal Models that are capable of processing information from different modalities, including images, videos, and text. <br>
          These are often referred to as <strong>Multimodal Large Language Models (MLLMs)</strong>. <br>
 <left>	<h3>Words...</h3>
</left>

 <div class="clearfix">
     <p>   Inspired by my own black cat, who sits beside me as I work on my laptop, I crafted this sentence to explain LLMs and the key concepts that will help you understand them. </p>
      <p>  <code>
            <it>"The cat is black."</it>
     </code> </p>
     <p>
        The word &quot;cat&quot; does not contain any inherent information about what a cat is, just from its letters. <br>
        The word can be represented as a number index, but this does not provide much information  </p>
	 
  <div class="clearfix">
            <div class="responsive-image"  src="img/cat_shadow_generated.png" style="width:30%" alt="..."/> 
	</div>
	 <p>Words can be represented as numerical indices. </p>

<p>For example, a dictionary of words might assign the word "cat" an index of 5 and "dog" an index of 10. However, the problem is that these indices themselves do not carry any meaning. </p>


<p>They are just placeholders for words, and the model has no inherent understanding of the relationships between words, such as "cat" and "dog". <br> </p>
	
<p>We need Meaningful Representations! Instead of simple indices, words can be represented by a list of feature attributes.  </p>

	 <p>For example, a dictionary entry for a word that contains various features:</p>

<list>
<ul> Part of Speech (POS): Whether the word is a noun, verb, adjective, etc. </ul>
<ul>  Description: A brief definition of the word. </ul>
<ul>  Usage: Examples of how the word is used in sentences. </ul>
</list>
	
	 <p>The key question in representing words is: <it>"What features should we use to capture the meaning of a word?"</it></p>
	 <ul>Should we include semantic features (e.g., synonyms, related concepts)?</ul>
	 <ul>Should we account for contextual usage (e.g., the word "bank" can refer to a financial institution or a riverbank)?</ul>


	 
 <left>	<h3>Tokenization</h3></left>
	 
	 <p>Tokenization is the process of breaking down a sentence into smaller units, usually words or subwords, which are called tokens.These tokens are then represented as numbers (indices) or fed into subsequent layers of a model. It converts text into units (tokens) that can be processed by models.</p>

	 <p>
Example: <br>
Sentence: <it>"The cat is black."</it> <br>
Tokenization (word-level): <code class="highlight-text">["The", "cat", "is", "black", "."]</code><br>
</p>
	 
<p> Now, a good question might be: why do we select word-level tokenization? Well, there are different types of tokenization, such as: word-level, subword-level, character-level,  n-grams etc.</p>
	 <p>For example, subword-level tokenizarion reduces vocabulary size compared to word-level tokenization. </p>
	 <p>Character-level tokenization can handle typos or misspellings better.</p>
	 <p>Word-level tokenization creates a more manageable and intuitive representation for analysis.It helps us to easier visualise the text data. </p>
<div>
 
	
 <left>	<h3>Embeddings</h3></left>
	
	<p>Once tokenization is complete, embedding is the process of converting these tokens (or token indices) into dense, continuous vector representations that capture the semantic meaning of the tokens. These embeddings help models understand relationships between words, their meanings, and context. </p>
	
	
	<list> Embedding models:
		<li>Word2Vec (2013): 
Introduced efficient learning of embeddings via CBOW and Skip-gram.
Continuous Bag of Words (CBOW): Predicts a target word from its surrounding context.
Continuous Skip-Gram Model: Predicts surrounding words from a target word.
</li>
		
		<li>
		GloVe (2014): 
Focused on global statistics to capture semantic relationships.
Constructs a co-occurrence matrix and factors it to learn vector representations for words.
</li>
		
		<li>
		FastText (2014):
An extension of Word2Vec that represents words as bags of character n-grams.
FastText can generate word embeddings for rare words or words not seen during training, by leveraging subword information (character-level embeddings).
</li>
	</list>
	<br>
	<p>While models like Word2Vec, GloVe, and FastText provided high-quality static embeddings, one limitation remained: words had the same vector representation regardless of context e.g., the word "bank" would have the same vector representation in "river bank" and "financial bank".

		<list>
<li>ELMo (2017): introduced contextualized embeddings using bidirectional LSTMs. </li>
<li>BERT (2018): revolutionized embeddings with a transformer-based bidirectional model.  </li>
<li>GPT-2 and GPT-3 (2019): pioneered large-scale, generative language models. </li>
<li> T5, RoBERTa, and ALBERT (2020): advanced transformer-based architectures, making them more efficient.  </li>
</list>
</p>
	
	
 <p><strong>Example:</strong> Tokens: [<code class="highlight-text">"the"</code>, <code class="highlight-text">"cat"</code>, <code class="highlight-text">"is"</code>, <code class="highlight-text">"black"</code>]</p>
        <p>The tokenized words are converted into vectors (word embeddings), typically of fixed size (e.g., 300 or 768 dimensions).</p>

        <p>The embedding process assigns a dense vector to each token that captures its meaning.</p>

       <p><strong>Important!</strong> As you can see, the sentence is now in lowercase and punctuation has been removed. For further details on common techniques for text preprocessing, such as: lowercasing, 
removing punctuation, stopword removal, stemming and lemmatization etc. </p>
            <strong>Example (simplified vectors):</strong>
            <ul>
				<li><code class="highlight-text">"the"</code> &rarr; [<code class="highlight-text">0.25, 0.89, -0.12, ...</code>] (300 or 768 numbers)</li>
            <li><code class="highlight-text">"cat"</code> &rarr; [<code class="highlight-text">0.72, -0.34, 0.65, ...</code>]</li>
            <li><code class="highlight-text">"is"</code> &rarr; [<code class="highlight-text">0.18, 0.49, -0.75, ...</code>]</li>
            <li><code class="highlight-text">"black"</code> &rarr; [<code class="highlight-text">0.93, -0.15, 0.24, ...</code>]</li>
        </ul>

	
 <left>	<h3>Transformer</h3></left>

	<p> The Transformer architecture is a deep learning model introduced in the paper "Attention is All You Need" by Vaswani et al. in 2017.</p>
	<p><strong>See paper:</strong> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need.<br> In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17). Curran Associates Inc., Red Hook, NY, USA, 6000–6010. Link: <a href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a>.
</p>
	
	 <h4>Positional Encoding</h4>

  <p>Transformers do not have recurrence or convolution to track word order.</p>

  <p><span class="highlight">Positional encoding</span> is added to give the model information about the position of each word in the sequence.</p>

  <p>The positional encoding is added to each word's embedding:</p>

  <code>[
  [0.1 + pos1, 0.2 + pos2, ..., 0.5 + <span class="highlight">posd</span>], <br>
  [0.6 + pos1, 0.7 + pos2, ..., 0.1 + <span class="highlight">posd</span>], <br>
  [0.9 + pos1, 0.3 + pos2, ..., 0.4 + <span class="highlight">posd</span>], <br>
  [0.3 + pos1, 0.8 + pos2, ..., 0.6 + <span class="highlight">posd</span>]
] <br></code>
	<br>

  <p>Where  <code><span class="highlight">pos1, pos2, ..., posd</span></code> are the positional encodings for each dimension, which help the model understand the sequence order.</p>

	
	
	<h4>Self-Attention Mechanism</h4>
	
	<p>Self-Attention Mechanism allows the Transformer to look at all the words in the sentence and decide which ones are important to focus on for each position. </p>
<p>Scaled Dot-Product Attention: Each word (or token) is represented by three vectors: <strong>Query (Q), Key (K), and Value (V)</strong>. For each word, attention scores are calculated using the dot product of the query with keys from other words in the sentence.</p>
<p>Example: When processing <strong>"cat"</strong>, it can attend to other words in the sentence to understand the context:</p>

	<code><span class="highlight">Attention("cat", "The") = 0.1 <br>
Attention("cat", "cat") = 0.5 <br>
Attention("cat", "is") = 0.3 <br>
		Attention("cat", "black") = 0.1 <br></span>
</code>
	
	
		<h4>Multi-Head Attention</h4>
<p>Instead of applying one attention mechanism, the Transformer uses multi-head attention, which allows the model to focus on different parts of the sentence from different perspectives (or "heads").
After processing the attention heads, the results are concatenated and passed through a linear transformation to combine the outputs of all heads.
</p>
		 
	
	

  <strong>Example: Multi-Head Attention</strong>

  <p class="sentence">"The cat is black".</p>

  <div class="head">
    <span class="highlight">Head 1:</span> might focus on the relationship between <span class="highlight">"The"</span> and <span class="highlight">"cat"</span> (i.e., focusing on the subject and its determiner).
  </div>

  <div class="head">
    <span class="highlight">Head 2:</span> might focus on <span class="highlight">"cat"</span> and <span class="highlight">"black"</span> (i.e., focusing on the relationship between the noun and its adjective).
  </div>

  <div class="head">
    <span class="highlight">Head 3:</span> might focus on the verb <span class="highlight">"is"</span> and <span class="highlight">"black"</span> to better understand the relationship between the verb and the adjective.
  </div>

  <p>Each head essentially provides a different perspective on the sentence, extracting different relationships between the words.</p>

	
	<p>Once the attention mechanism has adjusted the word representations based on the context, each word is passed through a feed-forward neural network.
This step applies two linear transformations with a ReLU activation in between. Each position is processed independently, and the result updates the representation of each word.
</p>
	
	<p> The Transformer repeats the self-attention and feed-forward steps multiple times (usually 6 or 12 layers). This allows the model to refine the word representations iteratively.
After multiple layers, the word embeddings of "The cat is black." now contain rich information about the relationships between the words.

	</p>
	
	<p>
	The decoder uses the output of the encoder to predict the next word in a sequence.
During training, the model learns to predict the next word based on a given input.
 For example, if the input is "The cat is", the decoder will try to predict "black" as the next word.
During inference (generation), the decoder generates the next word step by step. 
If we input "The cat is", the model might output "black". This predicted word is fed back into the decoder to predict the following word.
The decoder uses masked self-attention to ensure that it only attends to the previous words in the sequence (and not future words), ensuring that predictions are made in an autoregressive manner.
</p>
<!--	 ------------------------------------------------------->

	 	 	 <hr class="hr2"> 
	 </div></div></div></div>
<!-- Footer -->
<footer class="text-center text-lg-start bg-light text-muted">
  <!-- Section: Social media -->
<div class="container p-4">
			<div style="align-items: center">Contact</div>
    <!-- Section: Social media -->   
    <section class="mb-4">
      <!-- mail  -->
      <a class="btn btn-outline-light btn-floating m-1" data-tooltip="mc191@hw.ac.uk" href="mailto:mc191@hw.ac.uk"
        ><i class="fa fa-envelope"></i
      ></a>
		
      <!-- Linkedin -->
      <a class="btn btn-outline-light btn-floating m-1" data-tooltip="LinkedIn" href="https://www.linkedin.com/in/mirunaclinciu/"
        ><i class="fa fa-linkedin"></i
      ></a>
      <!-- Twitter -->
      <a class="btn btn-outline-light btn-floating m-1" data-tooltip="Twitter" href="https://twitter.com/MirunaClinciu">
        <i class="fa fa-twitter"></i
      ></a>
		
      <!-- Github -->
      <a class="btn btn-outline-light btn-floating m-1" data-tooltip="GitHub" href="https://github.com/MirunaClinciu"
        ><i class="fa fa-github"></i
      ></a>
    </section>
    <!-- Section: Social media -->
	</div>
  <!-- Copyright -->
  <div class="text-center p-4" style="background-color: rgba(0, 0, 0, 0.05);">
    © 2025 Copyright:
    <a class="text-reset fw-bold" href="https://www.mirunaclinciu.com/">Miruna Clinciu</a>
  </div>
  <!-- Copyright -->
</footer>
<!-- Footer -->
	
	
		</body>

</html>
